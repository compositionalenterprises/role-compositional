---
- name: (portal) Nginx conf is deployed
  template:
    src: "nginx_portal.conf.j2"
    dest: "/srv/{{ compositional_nginx_storage }}/nginx_conf.d/{{ environment_domain }}/portal.conf"
  notify: 'Restart Frontend'

- name: (portal) The MySQL database service is up and initialized
  # We're running a while loop to check to ensure that the mysql database has
  # initialized:
  #   https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking
  shell: 'docker exec -i database bash -c "while mysql -uroot -p{{ compositional_database_root_password }} -e \"SHOW DATABASES;\" 2>&1 | grep -e \"ERROR 2002\|ERROR 1045\"; do sleep 1; done; echo \"SHOW DATABASES SUCCEEDED\""'
  no_log: "{{ compositional_no_log }}"

- name: (portal) Set up the MySQL database
  shell: docker exec -i database mysql -uroot -p{{ compositional_database_root_password }} <<< "{{ compositional_portal_mysql_script }}"
  args:
    executable: '/bin/bash'
  no_log: "{{ compositional_no_log }}"

- name: (portal) Ensure portal_credentials directory exists
  file:
    path: "/srv/{{ compositional_portal_storage }}/portal_credentials"
    state: directory

- name: Create credentials files
  # So, let's review POSIX standards, shall we?
  #
  #     3.206 Line
  #     A sequence of zero or more non- <newline> characters plus a terminating
  #     <newline> character.
  #
  # So, these _files_, as we graciously call what we are templating below,
  # contain no lines. Now, wouldn't that mean that they are blank files? No! To
  # the contrary according to ruby developers around the world. These files are
  # to the standard of these blaggards who snub the very idea of
  # interoperability. So, be aware! These files **MUST** not have a line that
  # ends in a newline.
  template:
    src: 'portal_{{ item }}.j2'
    dest: "/srv/{{ compositional_portal_storage }}/portal_credentials/{{ item }}"
    mode: 0600
    owner: root
  loop:
    - 'production.key'
    - 'production.yml.enc'

- name: Deploy Container
  block:
    - name: (portal) The latest portal service is built and {{ compositional_portal_state }}
      docker_compose:
        project_name: portal
        definition:
          version: '3.6'
          services:
              portal:
                  image: "compositionalenterprises/portal:{{ compositional_portal_version }}"
                  container_name: portal
                  restart: always
                  volumes:
                      - "/srv/{{ compositional_portal_storage }}/portal_storage/:/app/storage/"
                      - "/srv/{{ compositional_portal_storage }}/portal_credentials/:/app/config/credentials/"
                      - "/srv/{{ compositional_nginx_storage }}/nginx_logs/:/srv/nginx_logs/"
                  networks:
                      - frontend
                      - backend
                  environment:
                    DB_HOST: 'database'
                    DB_NAME: 'portal'
                    DB_USER: 'portal'
                    DB_PASS: "{{ compositional_portal_backend_password }}"
                    BASE_URL: "{{ environment_domain }}"
                    ORG_NAME: "{{ compositional_portal_org_name }}"
                    ADMIN_EMAIL: "{{ compositional_portal_admin_email }}"
                    ADMIN_PASSWORD: "{{ compositional_portal_admin_password }}"
                    SERVICES: "{{ compositional_services | join(' ') }}"
                    RAILS_RELATIVE_URL_ROOT: '/portal'
                    HOST: "{{ environment_domain }}"
                    RUNDECK_API_TOKEN: "{{ ourcompose_rundeck_apitoken }}"
                    ENVIRONMENT_VAULT_PASSWORD: "{{ lookup('file', '../environment/.vault_pass') }}"
                    INITIAL_INSTALL: "{{ compositional_portal_initial_install }}"
                    ROLE_BRANCH: "{{ compositional_portal_role_branch }}"
                    OURCOMPOSEBOT_RO_KEY: "{{ compositional_portal_ourcomposebot_ro_key }}"
                  healthcheck:
                    test: "{{ compositional_portal_healthcheck }}"
                    interval: 5s
                    timeout: 30s
                    retries: 3

          networks:
              frontend:
                  external: true
              backend:
                  external: true
        pull: "{{ compositional_portal_pull }}"
        state: "{{ compositional_portal_state }}"
        restarted: "{{ compositional_portal_restarted }}"
      register: compositional_portal_output
      no_log: "{{ compositional_no_log }}"
  rescue:
    - name: (portal) Forcibly clean the docker cache
      command: docker system prune -a -f

    - name: (portal) The latest portal service is built and {{ compositional_portal_state }}
      docker_compose:
        project_name: portal
        definition:
          version: '3.6'
          services:
              portal:
                  image: "compositionalenterprises/portal:{{ compositional_portal_version }}"
                  container_name: portal
                  restart: always
                  volumes:
                      - "/srv/{{ compositional_portal_storage }}/portal_storage/:/app/storage/"
                      - "/srv/{{ compositional_portal_storage }}/portal_credentials/:/app/config/credentials/"
                      - "/srv/{{ compositional_nginx_storage }}/nginx_logs/:/srv/nginx_logs/"
                  networks:
                      - frontend
                      - backend
                  environment:
                    DB_HOST: 'database'
                    DB_NAME: 'portal'
                    DB_USER: 'portal'
                    DB_PASS: "{{ compositional_portal_backend_password }}"
                    BASE_URL: "{{ environment_domain }}"
                    ORG_NAME: "{{ compositional_portal_org_name }}"
                    ADMIN_EMAIL: "{{ compositional_portal_admin_email }}"
                    ADMIN_PASSWORD: "{{ compositional_portal_admin_password }}"
                    SERVICES: "{{ compositional_services | join(' ') }}"
                    RAILS_RELATIVE_URL_ROOT: '/portal'
                    HOST: "{{ environment_domain }}"
                    RUNDECK_API_TOKEN: "{{ ourcompose_rundeck_apitoken }}"
                    ENVIRONMENT_VAULT_PASSWORD: "{{ lookup('file', '../environment/.vault_pass') }}"
                    INITIAL_INSTALL: "{{ compositional_portal_initial_install }}"
                    ROLE_BRANCH: "{{ compositional_portal_role_branch }}"
                  healthcheck:
                    test: "{{ compositional_portal_healthcheck }}"
                    interval: 5s
                    timeout: 30s
                    retries: 3

          networks:
              frontend:
                  external: true
              backend:
                  external: true
        pull: "{{ compositional_portal_pull }}"
        state: "{{ compositional_portal_state }}"
        restarted: "{{ compositional_portal_restarted }}"
      register: compositional_portal_output
      no_log: "{{ compositional_no_log }}"

- name: (portal) The portal cron job for health checks
  cron:
    name: "Portal Health Check"
    minute: "*/10"
    hour: "*"
    day: "*"
    job: "/usr/bin/docker exec portal /app/bin/seeds/health_check.sh"

- name: (portal) The portal cron job to update the database with daily data
  cron:
    name: "Portal Full Backup"
    minute: "{{ compositional_portal_cron_minute }}"
    hour: "{{ compositional_portal_cron_hour }}"
    day: "{{ compositional_portal_cron_day }}"
    job: "/usr/bin/docker exec portal /app/bin/backup.sh"

#
# Bind Mountpoints
#

- name: (portal) Find source filesystem directory
  shell: for i in $(docker inspect --format {% raw %}{{.GraphDriver.Data.LowerDir}}{% endraw %} portal | tr ':' ' '); do if [[ -d ${i}{{ item['directory'] }} ]]; then echo ${i}; fi; done | head -n 1
  args:
    executable: /bin/bash
  when: not item['directory'].startswith('/srv')
  loop: "{{ compositional_portal_bind_mountpoints }}"
  register: compositional_portal_src_dirs

- debug:
    var: compositional_portal_src_dirs

- name: (portal) Register portal non-volume bind-mountpoints for proxy
  set_fact:
    compositional_proxy_bind_mountpoints: "{{ compositional_proxy_bind_mountpoints + [{'location': item['item']['location'], 'directory': item['stdout'] + item['item']['directory']}] }}"
  when: not item['item']['directory'].startswith('/srv')
  loop: "{{ compositional_portal_src_dirs['results'] }}"

- name: (portal) Register portal volume bind-mountpoints for proxy
  set_fact:
    compositional_proxy_bind_mountpoints: "{{ compositional_proxy_bind_mountpoints + [item] }}"
  when: item['directory'].startswith('/srv')
  loop: "{{ compositional_portal_bind_mountpoints }}"

#
# Admin Password
#
- name: (portal) Portal has all of its database migrations ran
  shell: "
    docker exec -i portal sh -c \"
      export RAILS_ENV=production;
      bundle exec rake db:migrate:status 2>/dev/null |
        sed '/^$/d' |
        tail -n 1 |
        tr -s ' ' |
        cut -d ' ' -f 2
      \"
    "
  register: compositional_portal_migrations
  until: "'up' in compositional_portal_migrations['stdout']"
  retries: 24
  delay: 5

- name: (portal) Create the admin account
  # Update or Add admin script example
  # See /app/bin/rake_admin.sh script on server for env vars
  shell: "
    docker exec -i
        -e PORTAL_ADMIN_CREATE_UPDATE=CREATE
        -e PORTAL_ADMIN_EMAIL=admin@{{ environment_domain }}
        -e PORTAL_ADMIN_PASSWORD={{ compositional_commandcenter_admin_password }}
        -e PORTAL_ADMIN_SEND_EMAIL_FLAG=NO portal
      '/app/bin/seeds/rake_admin.sh'
    "
  register: compositional_portal_create_admin
  failed_when: False
    #- compositional_portal_create_admin['rc'] not in [0, 127]
